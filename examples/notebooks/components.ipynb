{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d811690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Get my_package directory path from Notebook\n",
    "parent_dir = str(Path().resolve().parents[1])\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94284c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.transformers.models.functionals import create_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58bca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "hidden_dim = 200\n",
    "max_len = 5000\n",
    "batch_size = 32\n",
    "d_ff = hidden_dim\n",
    "num_head = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69f131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7]) torch.Size([3, 8])\n",
      "torch.Size([3, 7, 128]) torch.Size([3, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor(\n",
    "    [[ 1,3,4,2,0,0,0],\n",
    "    [ 1,3,4,4,2,0,0],\n",
    "    [ 1,2,0,0,0,0,0]]\n",
    ") # [ 3, 7]\n",
    "    \n",
    "# en_tensor = torch.randint(1, 10**4,[batch_size, seq_len], dtype=int)\n",
    "tgt = torch.tensor(\n",
    "    [[ 1,3,2,0,0,0,0,0],\n",
    "    [ 1,3,3,3,2,0,0,0],\n",
    "    [ 1,3,2,0,0,0,0,0]]\n",
    ") # [ 3, 8]\n",
    "\n",
    "print(src.shape, tgt.shape)\n",
    "\n",
    "embedding = nn.Embedding(10**4, embedding_dim=embed_dim)\n",
    "src_embedding = embedding(src)\n",
    "tgt_embedding = embedding(tgt)\n",
    "\n",
    "print(src_embedding.shape, tgt_embedding.shape)\n",
    "cross_padding_mask = create_cross_attention_mask(tgt, src)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2703674",
   "metadata": {},
   "source": [
    "# **Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c22ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.models.layers import EncoderLayer, DecoderLayer\n",
    "\n",
    "encoder_layer = EncoderLayer(\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_head,\n",
    ")    \n",
    "\n",
    "decoder_layer = DecoderLayer(\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_head,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6540f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "src_embedding.shape=torch.Size([3, 7, 128]) \n",
      "memory.shape=torch.Size([3, 7, 128]) \n",
      "logits.shape=torch.Size([3, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "memory = encoder_layer(\n",
    "    src_embedding,\n",
    "    self_is_causal = True\n",
    ")\n",
    "\n",
    "logits = decoder_layer(\n",
    "    tgt_embedding,\n",
    "    memory,\n",
    "    self_is_causal = True,\n",
    "    cross_padding_mask = cross_padding_mask\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n{src_embedding.shape=}\",\n",
    "    f\"\\n{memory.shape=}\",\n",
    "    f\"\\n{logits.shape=}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e755a",
   "metadata": {},
   "source": [
    "# **Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa23407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\francesco.paletta\\AppData\\Local\\anaconda3\\envs\\optimus\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(10000, 128)\n",
      "  (positional_encoding): PositionalEncoding()\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x EncoderLayer(\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (relu): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.transformers.models.encoders import Encoder\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size = 10**4,\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_head,\n",
    "    n_layers=2,\n",
    "    max_len=5000,\n",
    ")\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6fd680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "memory.shape=torch.Size([3, 7, 128])\n"
     ]
    }
   ],
   "source": [
    "memory = encoder(\n",
    "    src,\n",
    "    src_padding_mask = None,\n",
    "    self_is_causal = True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n{memory.shape=}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05daf44f",
   "metadata": {},
   "source": [
    "# **Decoders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7507b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(10000, 128)\n",
      "  (positional_encoding): PositionalEncoding()\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x DecoderLayer(\n",
      "      (self_attention): MultiHeadAttention(\n",
      "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attention): MultiHeadAttention(\n",
      "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (relu): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.transformers.models.decoders import Decoder\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size = 10**4,\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_head,\n",
    "    n_layers=2,\n",
    "    max_len=5000,\n",
    ")\n",
    "\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec8fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logits.shape=torch.Size([3, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "logits = decoder(\n",
    "    tgt,\n",
    "    memory,\n",
    "    self_is_causal=True,\n",
    "    cross_padding_mask=cross_padding_mask\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n{logits.shape=}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c0e7d",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec19c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vocab_size=10000, tgt_vocab_size=14641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimusTransformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(10000, 128)\n",
      "    (positional_encoding): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (relu): ReLU()\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(14641, 128)\n",
      "    (positional_encoding): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (cross_attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (relu): ReLU()\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output_projection): Linear(in_features=128, out_features=14641, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.transformers.models.optimus_model import OptimusTransformer\n",
    "\n",
    "config = {\n",
    "    'src_vocab_size': 10**4,\n",
    "    'tgt_vocab_size': 11**4,\n",
    "    'embed_dim': 128,\n",
    "    'num_heads': 16,\n",
    "    'n_layers': 1,\n",
    "    'hidden_dim': 256,\n",
    "    'max_seq_length': 100,\n",
    "    'dropout': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 10,\n",
    "    'warmup_steps': 4000,\n",
    "    'label_smoothing': 0.1\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = OptimusTransformer(\n",
    "src_vocab_size=config['src_vocab_size'],\n",
    "tgt_vocab_size=config['tgt_vocab_size'],\n",
    "n_layers=config['n_layers'],\n",
    "embed_dim=config['embed_dim'],\n",
    "num_heads=config['num_heads'],\n",
    "max_len=config['max_seq_length'],\n",
    "dropout=config['dropout'],\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad29ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 14641])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(\n",
    "        src,\n",
    "        tgt,\n",
    "        cross_padding_mask = cross_padding_mask,\n",
    "        tgt_is_causal = True,\n",
    "        memory_is_causal = True\n",
    "    )\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76092fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[False, False, False, False,  True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False, False, False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True,  True,  True,  True,  True]]]])\n",
      "tensor(21605)\n"
     ]
    }
   ],
   "source": [
    "start_seq = torch.tensor([[1],[1],[1]])\n",
    "cross_padding_mask = create_cross_attention_mask(start_seq, src)\n",
    "print(cross_padding_mask)\n",
    "with torch.no_grad():\n",
    "    output = model(\n",
    "        src,\n",
    "        start_seq,\n",
    "        cross_padding_mask = cross_padding_mask,\n",
    "        tgt_is_causal = True,\n",
    "        memory_is_causal = True\n",
    "    )\n",
    "\n",
    "print(torch.argmax(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cd8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Forward Pass ===\n",
      "Input source shape: torch.Size([3, 7])\n",
      "Input target shape: torch.Size([3, 8])\n",
      "Output shape: torch.Size([3, 8, 14641])\n",
      "\n",
      "=== Test Generazione ===\n",
      "Generated sequence shape: torch.Size([3, 21])\n",
      "First generated sequence: [1, 997, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997, 1488, 997]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test Forward Pass ===\")\n",
    "with torch.no_grad():\n",
    "    output = model(\n",
    "        src,\n",
    "        tgt,\n",
    "        cross_padding_mask = cross_padding_mask,\n",
    "        tgt_is_causal = True,\n",
    "        memory_is_causal = True\n",
    "    )\n",
    "    print(f\"Input source shape: {src.shape}\")\n",
    "    print(f\"Input target shape: {tgt.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # [batch_size, tgt_len, vocab_size]\n",
    "\n",
    "# Test generazione\n",
    "print(\"\\n=== Test Generazione ===\")\n",
    "with torch.no_grad():\n",
    "    generated = model.generate(src, max_len=20, start_token=1, end_token=2)\n",
    "    print(f\"Generated sequence shape: {generated.shape}\")\n",
    "    print(f\"First generated sequence: {generated[0].tolist()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
