{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c6eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Get my_package directory path from Notebook\n",
    "parent_dir = str(Path().resolve().parents[1])\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de897a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c1cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.models.functionals import (\n",
    "        generate_square_subsequent_mask, \n",
    "        mask_fill_combined,    \n",
    "        create_causal_mask,                                     \n",
    "        create_cross_attention_mask)\n",
    "\n",
    "from src.transformers.models.attentions import MultiHeadAttention as MhA\n",
    "MhA.scaled_dot_product_attention\n",
    "\n",
    "def clear_nan(tensor: torch.Tensor):\n",
    "        return torch.where(torch.isnan(tensor), \n",
    "                               torch.zeros_like(tensor), \n",
    "                               tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb89fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "hidden_dim = 200\n",
    "max_len = 5000\n",
    "batch_size = 32\n",
    "d_ff = hidden_dim\n",
    "num_head = 8\n",
    "src_seq_len = 4\n",
    "tgt_seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dff56d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7]) torch.Size([3, 1])\n",
      "torch.Size([3, 7, 128]) torch.Size([3, 1, 128])\n",
      "torch.Size([3, 8, 1, 16]) torch.Size([3, 8, 7, 16])\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor(\n",
    "    [[ 1,3,4,2,0,0,0],\n",
    "    [ 1,3,4,4,2,0,0],\n",
    "    [ 1,2,0,0,0,0,0]]\n",
    ")\n",
    "    \n",
    "# en_tensor = torch.randint(1, 10**4,[batch_size, seq_len], dtype=int)\n",
    "tgt = torch.tensor(\n",
    "    [[ 1],\n",
    "    [ 1],\n",
    "    [ 1]]\n",
    ")\n",
    "\n",
    "print(src.shape, tgt.shape)\n",
    "\n",
    "embedding = nn.Embedding(10**4, embedding_dim=embed_dim)\n",
    "src_embedding = embedding(src)\n",
    "tgt_embedding = embedding(tgt)\n",
    "\n",
    "print(src_embedding.shape, tgt_embedding.shape)\n",
    "\n",
    "batch_size, seq_len_src, embed_dim = src_embedding.shape\n",
    "_, seq_len_tgt, _ = tgt_embedding.shape\n",
    "\n",
    "linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "Q = linear(tgt_embedding).view(batch_size, seq_len_tgt, num_head, embed_dim//num_head).transpose(1, 2)\n",
    "K = linear(src_embedding).view(batch_size, seq_len_src, num_head, embed_dim//num_head).transpose(1, 2)\n",
    "V = linear(src_embedding).view(batch_size, seq_len_src, num_head, embed_dim//num_head).transpose(1, 2)\n",
    "\n",
    "print(Q.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd2cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.0000e+09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -1.0000e+09, -1.0000e+09]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n"
     ]
    }
   ],
   "source": [
    "print(generate_square_subsequent_mask(src.shape[-1]))\n",
    "print(create_cross_attention_mask(tgt, src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669fb67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 1, 1])\n",
      "torch.Size([3, 1, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "tgt_key_padding_mask = create_cross_attention_mask(tgt, tgt)\n",
    "src_key_padding_mask = create_cross_attention_mask(src, src)\n",
    "memory_key_padding_mask = src_key_padding_mask\n",
    "\n",
    "print(tgt_key_padding_mask.shape)\n",
    "print(src_key_padding_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff3d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoresShape: torch.Size([3, 8, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0000e+09, -1.0000e+09, -5.0582e-02,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  8.9814e-02,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0008e-01,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  8.3540e-02,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  1.5477e-01,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  2.2460e-01,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]],\n",
       "\n",
       "\n",
       "        [[[-1.0000e+09, -1.0000e+09, -5.0582e-02,  ..., -5.2948e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -7.3664e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.3168e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  8.9814e-02,  ..., -1.8966e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.7752e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -6.4979e-03,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0008e-01,  ..., -3.3024e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.2765e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.9630e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  8.3540e-02,  ..., -1.7587e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  4.9783e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -8.0444e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  1.5477e-01,  ...,  9.3753e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.9494e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -8.8899e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09,  2.2460e-01,  ...,  3.9077e-02,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  6.1772e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -6.4993e-01,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]],\n",
       "\n",
       "\n",
       "        [[[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "         [[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          ...,\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = K @ K.transpose(-2,-1) / math.sqrt(K.size(-1))\n",
    "print('ScoresShape:', scores.shape)\n",
    "\n",
    "src_key_padding_mask = ( src == 0)\n",
    "\n",
    "mask_fill_combined(\n",
    "    attention_scores=scores,\n",
    "    attn_mask=create_causal_mask(seq_len=seq_len_src),\n",
    "    padding_mask=src_key_padding_mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6921b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoresShape: torch.Size([3, 8, 7, 7])\n",
      "AttentionMaskShape: torch.Size([3, 1, 1, 7])\n",
      "torch.Size([3, 8, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "scores = K @ K.transpose(-2,-1) / math.sqrt(K.size(-1))\n",
    "print('ScoresShape:', scores.shape)\n",
    "\n",
    "src_key_padding_mask = ( src == 0)\n",
    "\n",
    "print('AttentionMaskShape:',src_key_padding_mask.unsqueeze(1).unsqueeze(2).shape)\n",
    "scores = scores.masked_fill(src_key_padding_mask.unsqueeze(1).unsqueeze(2), -1e9)\n",
    "\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc73344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoresShape: torch.Size([3, 8, 7, 7])\n",
      "AttentionMaskShape: torch.Size([3, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mScoresShape:\u001b[39m\u001b[33m'\u001b[39m, scores.shape)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAttentionMaskShape:\u001b[39m\u001b[33m'\u001b[39m,src_key_padding_mask.shape)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m attn_weight = torch.dropout(torch.softmax(\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m, -\u001b[32m1\u001b[39m), \u001b[32m.1\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAttentionWeightShape:\u001b[39m\u001b[33m'\u001b[39m, attn_weight.shape)\n\u001b[32m     11\u001b[39m context = (attn_weight @ V ).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous().view(batch_size, seq_len_src, embed_dim)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (7) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Self-Attention Encoder\n",
    "\n",
    "scores = K @ K.transpose(-2,-1) / math.sqrt(K.size(-1))\n",
    "print('ScoresShape:', scores.shape)\n",
    "\n",
    "\n",
    "print('AttentionMaskShape:',src_key_padding_mask.shape)\n",
    "\n",
    "attn_weight = torch.dropout(torch.softmax(scores + src_key_padding_mask, -1), .1, train=True)\n",
    "print('AttentionWeightShape:', attn_weight.shape)\n",
    "context = (attn_weight @ V ).transpose(1, 2).contiguous().view(batch_size, seq_len_src, embed_dim)\n",
    "print('ContextShape:', context.shape)\n",
    "print(attn_weight[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f43757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1347,  0.0133, -0.1113,  0.5884, -0.4262, -0.3468, -0.8244, -0.1808,\n",
      "         0.6137, -0.1443,  0.0688, -0.1342, -0.5640, -0.5474, -0.0077,  0.0428,\n",
      "         0.1654,  0.3951, -0.0045, -0.0851, -0.0373,  0.3932, -0.1892, -0.1142,\n",
      "        -0.5534,  0.2787,  0.5795, -0.1955, -0.6816,  0.1760, -0.3149,  0.2758,\n",
      "        -0.5144, -0.7355,  0.0139, -0.5996, -0.7749,  0.0522, -0.0306, -0.4824,\n",
      "         0.7699, -0.0389, -0.3984, -0.0889, -0.3997, -0.4470, -0.4969,  0.0485,\n",
      "        -0.5229,  0.3915, -0.1164,  0.1595, -0.2984, -0.4077,  0.2486,  0.6055,\n",
      "        -0.0638,  0.5479,  0.3315, -0.2772,  0.2612, -0.1980,  0.0249, -0.6667,\n",
      "         0.2648,  0.0666,  0.2216, -0.3258, -0.0243,  0.2828, -0.4516, -0.1699,\n",
      "         0.3944, -0.2315,  0.2097, -0.1331, -0.1458, -0.0117, -0.2269,  0.0645,\n",
      "        -0.0752, -0.5169,  0.2199,  0.2410,  0.0887, -0.1910, -0.7426,  0.3091,\n",
      "        -0.1739,  0.5805, -0.4018,  0.2240, -0.1021, -0.1421, -0.5046, -0.1238,\n",
      "        -0.4964, -0.1431,  0.6364, -0.3089, -0.7468, -0.0108, -0.4904, -0.2952,\n",
      "        -0.1935,  0.1460,  0.2562, -0.4751,  0.5520,  0.4102,  0.0425,  0.4672,\n",
      "        -0.0859, -0.0411, -0.2883,  0.5378,  0.1384, -0.2897,  0.7098, -0.2703,\n",
      "        -0.5221, -0.1101, -0.0999,  1.1124,  0.3975,  0.3471, -0.0906, -0.2765],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.6059,  0.0622, -0.3816,  1.0156, -0.2848, -0.0746, -0.8497, -0.4139,\n",
      "         0.0936, -0.2953, -0.2048, -0.8318, -1.0026, -0.4831, -0.3251,  0.1000,\n",
      "         0.2727,  0.8847,  0.1739, -0.1616,  0.2425,  0.3891, -0.3575, -0.0650,\n",
      "        -0.3966,  0.4913,  1.1781, -0.2939, -1.0872,  0.6879, -0.3132,  0.5529,\n",
      "        -0.6697, -1.1009,  0.2568, -0.9954, -1.0755,  0.1076,  0.1649, -0.6021,\n",
      "         1.2274, -0.0567, -0.4667, -0.0611, -0.6336, -0.5903, -0.6612,  0.2109,\n",
      "        -0.5714,  0.8633, -0.2643, -0.2143, -0.1848, -0.4139, -0.0158,  0.8200,\n",
      "         0.4727,  0.2177,  0.2431,  0.3006,  0.5411, -0.4230, -0.3749, -0.8854,\n",
      "        -0.0645, -0.0200,  0.0651, -0.5413, -0.1246,  0.1967, -0.5378, -0.4337,\n",
      "         0.8598, -0.2244,  0.4302, -0.6175,  0.3393,  0.1634,  0.2612, -0.1195,\n",
      "        -0.3185, -0.9244,  0.1144,  0.1539,  0.3010,  0.3417, -0.7420,  0.6217,\n",
      "        -0.3912,  0.5425, -0.8664,  0.1020, -0.0544,  0.4056, -0.3683, -0.6904,\n",
      "        -0.9145, -0.1032,  1.0265, -0.6922, -1.1696,  0.1521, -0.3896, -0.3784,\n",
      "        -0.2015, -0.0264,  0.2834, -0.2699,  0.9843,  0.5817,  0.2705,  0.7355,\n",
      "        -0.3912, -0.1030, -0.4551,  0.5843,  0.3082, -0.1962,  0.9510, -0.6008,\n",
      "        -0.4949, -0.0639, -0.0921,  1.6921,  0.3910,  0.6708,  0.0333, -0.7552],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0513,  0.1302, -0.2335,  0.4351, -0.2439, -0.4529, -0.4513, -0.5788,\n",
      "         0.5663, -0.0128,  0.4014,  0.2323, -0.6712, -0.3513,  0.2059,  0.3413,\n",
      "        -0.0641,  0.0750, -0.3183,  0.1237,  0.0521,  0.5430,  0.0726, -0.3677,\n",
      "        -0.4254,  0.5011,  0.4258, -0.1839, -0.4955,  0.0518,  0.0275,  0.2517,\n",
      "        -0.6258, -0.8546,  0.5447, -0.7927, -0.1985,  0.1468,  0.1411, -0.5716,\n",
      "         0.4137, -0.2253, -0.1689, -0.1882, -0.2178, -0.2924, -0.2508,  0.1052,\n",
      "        -0.2599,  0.4079,  0.1911, -0.6006, -0.4091, -0.4748,  0.0489,  0.6100,\n",
      "         0.1592,  0.7539,  0.0864,  0.4191,  0.0790, -0.3813,  0.0713, -0.1805,\n",
      "         0.4939,  0.1152, -0.0190, -0.3245,  0.1337,  0.1763, -0.0805, -0.1979,\n",
      "         0.5939, -0.0605,  0.1266, -0.1787, -0.3789, -0.4111, -0.0677, -0.1969,\n",
      "         0.0751, -0.1444,  0.1619,  0.0687, -0.0099, -0.2983, -0.6664,  0.3720,\n",
      "        -0.1363,  0.4247, -0.1188,  0.1500, -0.0076, -0.0646, -0.4191, -0.0154,\n",
      "        -0.1613, -0.1851,  0.5824, -0.1358, -0.5358,  0.0129, -0.3062, -0.3137,\n",
      "        -0.1533,  0.0871,  0.3564, -0.6565,  0.3527,  0.1986,  0.0116,  0.3977,\n",
      "        -0.3367,  0.3307, -0.0038,  0.3529,  0.0458, -0.5133,  0.7671, -0.3542,\n",
      "        -0.8516, -0.1086, -0.3632,  1.2679,  0.4355,  0.1750,  0.0124, -0.3543],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    MhA.scaled_dot_product_attention(\n",
    "        K, K, V,\n",
    "        attn_mask=src_key_padding_mask\n",
    "    )[0]\n",
    "    .transpose(1, 2)\n",
    "    .contiguous()\n",
    "    .view(batch_size, seq_len_src, embed_dim)[0][0]\n",
    ")\n",
    "\n",
    "print(\n",
    "    MhA.scaled_dot_product_attention(\n",
    "        Q, Q, Q,\n",
    "        attn_mask=tgt_key_padding_mask\n",
    "    )[0]\n",
    "    .transpose(1, 2)\n",
    "    .contiguous()\n",
    "    .view(batch_size, seq_len_tgt, embed_dim)[0][0]\n",
    ")\n",
    "\n",
    "print(\n",
    "    MhA.scaled_dot_product_attention(\n",
    "        Q, K, V,\n",
    "        attn_mask=memory_key_padding_mask\n",
    "    )[0]\n",
    "    .transpose(1, 2)\n",
    "    .contiguous()\n",
    "    .view(batch_size, seq_len_tgt, embed_dim)[0][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eaf942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 7, 16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(attn_weight @ V).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8306ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoresShape: torch.Size([3, 8, 1, 1])\n",
      "AttentionMaskShape: torch.Size([1, 1])\n",
      "AttentionWeightShape: torch.Size([3, 8, 1, 1])\n",
      "ContextShape: torch.Size([3, 1, 128])\n",
      "tensor([[1.1111]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Self-Attention \n",
    "\n",
    "scores = Q @ Q.transpose(-2,-1) / math.sqrt(Q.size(-1))\n",
    "print('ScoresShape:', scores.shape)\n",
    "\n",
    "attn_mask = generate_square_subsequent_mask(tgt.shape[-1])\n",
    "print('AttentionMaskShape:',attn_mask.shape)\n",
    "\n",
    "attn_weight = torch.dropout(torch.softmax(scores + attn_mask, -1), .1, train=True)\n",
    "print('AttentionWeightShape:', attn_weight.shape)\n",
    "context = (attn_weight @ Q ).transpose(1, 2).contiguous().view(batch_size, seq_len_tgt, embed_dim)\n",
    "print('ContextShape:', context.shape)\n",
    "print(attn_weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScoresShape: torch.Size([3, 8, 1, 7])\n",
      "AttentionMaskShape: torch.Size([3, 1, 1, 7])\n",
      "AttentionWeightShape: torch.Size([3, 8, 1, 7])\n",
      "ContextShape: torch.Size([3, 1, 128])\n",
      "tensor([[0.5467, 0.2879, 0.0000, 0.1352, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Attention\n",
    "scores = Q @ K.transpose(-2,-1) / math.sqrt(Q.size(-1))\n",
    "print('ScoresShape:', scores.shape)\n",
    "\n",
    "attn_mask = F._canonical_mask(\n",
    "    mask=create_cross_attention_mask(tgt, src),\n",
    "    mask_name='attn_mask',\n",
    "    other_type=F._none_or_dtype(attn_mask),\n",
    "    other_name=\"mask\",\n",
    "    target_type=torch.float,\n",
    "\n",
    ")    \n",
    "print('AttentionMaskShape:',attn_mask.shape)\n",
    "\n",
    "attn_weight = clear_nan(\n",
    "    torch.dropout(torch.softmax(scores + attn_mask, -1), .1, train=True)\n",
    ")\n",
    "print('AttentionWeightShape:', attn_weight.shape)\n",
    "\n",
    "context = (\n",
    "    (attn_weight @ V ).transpose(1, 2).contiguous().view(batch_size, seq_len_tgt, embed_dim)\n",
    ")\n",
    "print('ContextShape:', context.shape)\n",
    "print(attn_weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., -inf, -inf, -inf]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., -inf, -inf]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., -inf, -inf, -inf, -inf, -inf]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
